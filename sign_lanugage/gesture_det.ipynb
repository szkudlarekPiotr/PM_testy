{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f82107",
   "metadata": {},
   "source": [
    "# Model zainspirowany filmem znalezionym na yt:https://youtu.be/doDUihpj6ro, zmieniony jedynie na potrzeby mojego projektu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10628c8",
   "metadata": {},
   "source": [
    "### Import modułów używanych do projektu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414658bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ac5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic          #import modelu wykrywającego cialo mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils      #import narzędzi do oznaczania detekcji na obrazie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d8d5b",
   "metadata": {},
   "source": [
    "### Funkcja pozwalająca przeprocesować klatki filmu modelowi mediapipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c57798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_det(image,model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #konwersja kolorów BGR na RGB klatki\n",
    "    image.flags.writeable = False                  #zarządzanie pamięcią dla np.array\n",
    "    results = model.process(image)                 #processowanie klatki za pomocą modelu mediapipe\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acedea78",
   "metadata": {},
   "source": [
    "### Funkcja zwracająca klatki z narysowanymi liniamii dłoni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c453796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hands(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10cae1",
   "metadata": {},
   "source": [
    "### Funkcja otwierająca oraz zapisująca wideo, oraz implementująca poprzednie funkcje napisane wyżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae59bad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('trim1.mp4')                            #otwarcie pliku ze ścieżki\n",
    "size = (int(cap.get(3)), int(cap.get(4)))                      #określenie rozdzielczości\n",
    "fps =  int(cap.get(cv2.CAP_PROP_FPS))                          #określenie fps filmu\n",
    "output = cv2.VideoWriter('test1.mp4', cv2.VideoWriter.fourcc(*'mp4v'), fps,size)              #funkcja opencv zapisująca wynik\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.3, min_tracking_confidence = 0.3) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()  #odczytanie klatek z filmu, ret - ilość pozostałych klatek, frame - \"obraz\" klatki\n",
    "        if not ret:                                                 # przerwanie pętli, kiedy nie ma juz pozostałych klatek do przerobienia\n",
    "            break\n",
    "            \n",
    "        image, results = mediapipe_det(frame, holistic)             # procesowanie klatki przez model mediapipe\n",
    "        \n",
    "        draw_hands(image, results)                                  # rysowanie lini dłoni\n",
    "            \n",
    "        output.write(image)                                         # zapisywanie zmienionych klatek i łączenie je z powrotem w film\n",
    "\n",
    "        cv2.imshow(\"OpenCV Feed\", image)                            # podgląd \"live\"\n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):                       # zamknięcie okna opencv za pomoca przycisku 'q'\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    output.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_language",
   "language": "python",
   "name": "sign_language"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
